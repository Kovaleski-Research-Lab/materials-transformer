_target_: models.mode-mlp.ModeMLP

layers: [32, 64, 128, 32]
activation: 'relu'
dropout: 0.0

# General Parameters

optimizer:
  _target_: torch.optim.Adam
  _partial_: True
  lr: 1.e-4
  betas: [0.9, 0.999] # default
  weight_decay: 0.0 # default

lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: True
  T_max: 100
  eta_min: 1.e-6

num_modes: 12
num_design_conf: 9
loss_func: 'mse'