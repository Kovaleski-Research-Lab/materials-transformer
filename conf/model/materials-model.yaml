_target_: models.smiles_transformer.SmilesTransformer

# Parameters

input_dim: 1
model_dim: 496
num_heads: 8
encoder_depth: 4
decoder_depth: 4
rows: 80
cols: 160
dropout: 0.05
target_vocab_size: 26 # 23 unique chars in the dataset + 3 specials
lambda_mw: 0.0 # controlling controbution of mol weight loss term

# General Parameters

optimizer:
  _target_: torch.optim.Adam
  _partial_: True
  lr: 1.e-4
  betas: [0.9, 0.999] # default
  weight_decay: 0.0 # default

lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  _partial_: True
  T_0: 100
  T_mult: 2
  eta_min: 1.e-5

loss_func: 'bce'
seq_len: 500