_target_: pytorch_lightning.Trainer

accelerator: auto
devices: auto
max_epochs: 100
precision: "32" #"16-mixed"
log_every_n_steps: 1

logger:
  _target_: pytorch_lightning.loggers.MLFlowLogger
  experiment_name: ${project_name}
  run_name: run11-rl
  tracking_uri: "file://${paths.results}/mlruns"
  log_model: False # ModelCheckpoint callback handles this

# --- Callbacks Configuration ---
callbacks:
  # 1. Model Checkpointing
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val_loss"
    mode: "min"
    save_top_k: 1
    save_last: True
    #dirpath: "${paths.results}/checkpoints/" wanna let MLflow handle this
    filename: "best-model"
    auto_insert_metric_name: False

  # 2. Early Stopping
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val_loss"
    mode: "min"
    patience: 10

  # 3. Learning Rate Monitoring
  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"

  # 4. (Custom) Smiles Pred Logger
  - _target_: utils.callbacks.SMILES_Prediction_Logger