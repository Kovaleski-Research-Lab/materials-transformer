_target_: pytorch_lightning.Trainer

accelerator: auto
devices: auto
max_epochs: 100
precision: "16-mixed"
log_every_n_steps: 1

logger:
  _target_: pytorch_lightning.loggers.MLFlowLogger
  experiment_name: ${project_name}
  tracking_uri: ${paths.logs}/mlruns
  log_model: true 

# --- Callbacks Configuration ---
callbacks:
  # 1. Model Checkpointing
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val_loss"
    mode: "min"
    save_top_k: 1
    dirpath: "checkpoints/"
    filename: "{epoch}-{val_loss:.2f}"

  # 2. Early Stopping
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val_loss"
    mode: "min"
    patience: 15

  # 3. Learning Rate Monitoring
  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"